PREHOOK: query: USE default
PREHOOK: type: SWITCHDATABASE
PREHOOK: Input: database:default
POSTHOOK: query: USE default
POSTHOOK: type: SWITCHDATABASE
POSTHOOK: Input: database:default
PREHOOK: query: drop table tstsrcpart
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table tstsrcpart
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table tstsrcpart like srcpart
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@tstsrcpart
POSTHOOK: query: create table tstsrcpart like srcpart
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@tstsrcpart
PREHOOK: query: -- EXCLUDE_HADOOP_MAJOR_VERSIONS(0.20)
-- The version of GzipCodec that is provided in Hadoop 0.20 silently ignores
-- file format errors. However, versions of Hadoop that include
-- HADOOP-6835 (e.g. 0.23 and 1.x) cause a Wrong File Format exception
-- to be thrown during the LOAD step. This former behavior is tested
-- in clientpositive/archive_corrupt.q

load data local inpath '../../data/files/archive_corrupt.rc' overwrite into table tstsrcpart partition (ds='2008-04-08', hr='11')
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@tstsrcpart
Failed with exception Wrong file format. Please check the file's format.
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask
