PREHOOK: query: -- Tests truncating a column from a list bucketing table

-- INCLUDE_HADOOP_MAJOR_VERSIONS(0.23)

CREATE TABLE test_tab (key STRING, value STRING) PARTITIONED BY (part STRING) STORED AS RCFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@test_tab
POSTHOOK: query: -- Tests truncating a column from a list bucketing table

-- INCLUDE_HADOOP_MAJOR_VERSIONS(0.23)

CREATE TABLE test_tab (key STRING, value STRING) PARTITIONED BY (part STRING) STORED AS RCFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@test_tab
PREHOOK: query: ALTER TABLE test_tab
SKEWED BY (key) ON ("484")
STORED AS DIRECTORIES
PREHOOK: type: ALTERTABLE_SKEWED
PREHOOK: Input: default@test_tab
PREHOOK: Output: default@test_tab
POSTHOOK: query: ALTER TABLE test_tab
SKEWED BY (key) ON ("484")
STORED AS DIRECTORIES
POSTHOOK: type: ALTERTABLE_SKEWED
POSTHOOK: Input: default@test_tab
POSTHOOK: Output: default@test_tab
PREHOOK: query: INSERT OVERWRITE TABLE test_tab PARTITION (part = '1') SELECT * FROM src
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@test_tab@part=1
POSTHOOK: query: INSERT OVERWRITE TABLE test_tab PARTITION (part = '1') SELECT * FROM src
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@test_tab@part=1
POSTHOOK: Lineage: test_tab PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: test_tab PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
PREHOOK: type: QUERY
PREHOOK: Input: default@test_tab
PREHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_tab
POSTHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
0	val_0	1
0	val_0	1
0	val_0	1
PREHOOK: query: TRUNCATE TABLE test_tab PARTITION (part ='1') COLUMNS (value)
PREHOOK: type: TRUNCATETABLE
PREHOOK: Input: default@test_tab
PREHOOK: Output: default@test_tab@part=1
POSTHOOK: query: TRUNCATE TABLE test_tab PARTITION (part ='1') COLUMNS (value)
POSTHOOK: type: TRUNCATETABLE
POSTHOOK: Input: default@test_tab
POSTHOOK: Output: default@test_tab@part=1
PREHOOK: query: -- In the following select statements the list bucketing optimization should still be used
-- In both cases value should be null

EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '484'
PREHOOK: type: QUERY
POSTHOOK: query: -- In the following select statements the list bucketing optimization should still be used
-- In both cases value should be null

EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '484'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            test_tab
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_WHERE
         AND
            =
               TOK_TABLE_OR_COL
                  part
               '1'
            =
               TOK_TABLE_OR_COL
                  key
               '484'


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Partition Description:
          Partition
            input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
            partition values:
              part 1
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.test_tab
              numFiles 2
              numRows 0
              partition_columns part
              partition_columns.types string
              rawDataSize 0
              serialization.ddl struct test_tab { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              totalSize 1761
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
          
              input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.test_tab
                partition_columns part
                partition_columns.types string
                serialization.ddl struct test_tab { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              name: default.test_tab
            name: default.test_tab
      Processor Tree:
        TableScan
          alias: test_tab
          Statistics: Num rows: 17 Data size: 1761 Basic stats: COMPLETE Column stats: NONE
          GatherStats: false
          Filter Operator
            isSamplingPred: false
            predicate: (key = '484') (type: boolean)
            Statistics: Num rows: 8 Data size: 828 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: '484' (type: string), value (type: string), '1' (type: string)
              outputColumnNames: _col0, _col1, _col2
              Statistics: Num rows: 8 Data size: 828 Basic stats: COMPLETE Column stats: NONE
              ListSink

PREHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '484'
PREHOOK: type: QUERY
PREHOOK: Input: default@test_tab
PREHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '484'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_tab
POSTHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
484	NULL	1
PREHOOK: query: EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '0'
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN EXTENDED SELECT * FROM test_tab WHERE part = '1' AND key = '0'
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            test_tab
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF
      TOK_WHERE
         AND
            =
               TOK_TABLE_OR_COL
                  part
               '1'
            =
               TOK_TABLE_OR_COL
                  key
               '0'


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Partition Description:
          Partition
            input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
            partition values:
              part 1
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns key,value
              columns.comments 
              columns.types string:string
#### A masked pattern was here ####
              name default.test_tab
              numFiles 2
              numRows 0
              partition_columns part
              partition_columns.types string
              rawDataSize 0
              serialization.ddl struct test_tab { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              totalSize 1761
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
          
              input format: org.apache.hadoop.hive.ql.io.RCFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.RCFileOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.comments 
                columns.types string:string
#### A masked pattern was here ####
                name default.test_tab
                partition_columns part
                partition_columns.types string
                serialization.ddl struct test_tab { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
              name: default.test_tab
            name: default.test_tab
      Processor Tree:
        TableScan
          alias: test_tab
          Statistics: Num rows: 17 Data size: 1761 Basic stats: COMPLETE Column stats: NONE
          GatherStats: false
          Filter Operator
            isSamplingPred: false
            predicate: (key = '0') (type: boolean)
            Statistics: Num rows: 8 Data size: 828 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: '0' (type: string), value (type: string), '1' (type: string)
              outputColumnNames: _col0, _col1, _col2
              Statistics: Num rows: 8 Data size: 828 Basic stats: COMPLETE Column stats: NONE
              ListSink

PREHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
PREHOOK: type: QUERY
PREHOOK: Input: default@test_tab
PREHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
POSTHOOK: query: SELECT * FROM test_tab WHERE part = '1' AND key = '0'
POSTHOOK: type: QUERY
POSTHOOK: Input: default@test_tab
POSTHOOK: Input: default@test_tab@part=1
#### A masked pattern was here ####
0	NULL	1
0	NULL	1
0	NULL	1
